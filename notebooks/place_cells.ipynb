{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e33fd525",
   "metadata": {},
   "source": [
    "# Hippocampal place cell sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbca421",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# suppress warnings\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "# imports\n",
    "import math\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from scipy import signal\n",
    "import seaborn as sns\n",
    "import tqdm\n",
    "import pynapple as nap\n",
    "import pynacollada as nac\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "import textwrap\n",
    "\n",
    "# necessary for animation\n",
    "import nemos as nmo\n",
    "plt.style.use(nmo.styles.plot_style)\n",
    "\n",
    "# define helper functions\n",
    "def printeval(expr):\n",
    "    print(expr, \" = \\n\", textwrap.indent(eval(expr).__str__(), 4*' '),\"\\n\")\n",
    "\n",
    "def plot_place_fields(pf, axs, title=None, xlabel=None):\n",
    "    for c, ax in zip(pf, axs):\n",
    "        ax.fill_between(pf[c].index.values, np.zeros_like(pf[c]), pf[c].values)\n",
    "        ax.set_yticks([])\n",
    "        # ax.set_xticks([])\n",
    "    if title is not None:\n",
    "        axs[0].set_title(title)\n",
    "    if xlabel is not None:\n",
    "        axs[-1].set_xlabel(xlabel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b352302b",
   "metadata": {},
   "source": [
    "## Background"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16981897",
   "metadata": {},
   "source": [
    "## Exploring the data\n",
    "    \n",
    "The data set we'll be looking at is from the manuscript [Diversity in neural firing dynamics supports both rigid and learned hippocampal sequences](https://www.science.org/doi/10.1126/science.aad1935). In this study, the authors collected electrophisiology data in rats across multiple sites in layer CA1 of hippocampus to extract the LFP alongside spiking activity of many simultaneous pyramidal units. In each recording session, data were collected while the rats explored a novel environment (a linear or circular track), as well as during sleep before and after exploration. In our following analyses, we'll focus on the exploration period of a single rat and recording session.\n",
    "\n",
    "The full dataset for this study can be accessed on [DANDI](https://dandiarchive.org/dandiset/000044/0.210812.1516). Since the file size of a recording session can be large from the LFP saved for each recorded channel, we'll use a smaller file that contains the spiking activity and the LFP from a single, representative channel, which is hosted on [OSF](https://osf.io/2dfvp). This smaller file, like the original data, is saved as an [NWB](https://www.nwb.org) file.\n",
    "\n",
    "For this tutorial, we can use the pynacollada function `load_data` and the tutorial name `\"place_cells\"` to fetch the data. Under the hood, this function uses pynapple to load in the NWB file, which returns a dictionary of pynapple objects that have been extracted from the file. The next sections will explore each of these fields (excluding `\"theta_phase\"`, which we'll compute ourselves later on)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed56ba72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pynacollada data set\n",
    "data = nac.load_data(\"place_cells\")\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699d53f2",
   "metadata": {},
   "source": [
    "### `units` \n",
    "    \n",
    "The `units` field is a [`TsGroup`](https://pynapple.org/generated/pynapple.TsGroup.html#pynapple.TsGroup): a collection of [`Ts`](https://pynapple.org/generated/pynapple.Ts.html) objects containing the spike times of each unit, where the \"Index\" is the unit number or key. Each unit has the following [metadata](https://pynapple.org/user_guide/03_metadata.html):\n",
    "- **rate**: computed by pynapple, is the average firing rate of the neuron across all recorded time points.\n",
    "- **location**, **shank**, and **cell_type**: variables saved and imported from the original data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b07440",
   "metadata": {},
   "outputs": [],
   "source": [
    "printeval(\"data['units']\")    # print the entire TsGroup object\n",
    "printeval(\"data['units'][1]\") # print the Ts object corresponding to unit 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c8f8b1",
   "metadata": {},
   "source": [
    "### `rem`, `nrem`, and `forward_ep`\n",
    "\n",
    "\n",
    "The next three objects; `rem`, `nrem`, and `forward_ep`; are all [`IntervalSet`](https://pynapple.org/generated/pynapple.IntervalSet.html#pynapple.IntervalSet) objects containing time windows of REM sleep, nREM sleep, and forward runs down the linear maze, respectively. All intervals in `forward_ep` occur in the middle of the session, while `rem` and `nrem` both contain sleep epochs that occur before and after exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475a20b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "printeval(\"data['rem']\")            # print the REM intervals\n",
    "printeval(\"data['nrem']\")           # print the nREM intervals\n",
    "printeval(\"data['forward_ep']\")     # print the forward_ep intervals\n",
    "\n",
    "# grab the first time stamp to plot relative measure of time within session\n",
    "t_start = data[\"nrem\"].start[0]\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(10,2), constrained_layout=True)\n",
    "\n",
    "# plot blue rectangles for each \"rem\" interval\n",
    "sp1 = [ax.axvspan((iset.start[0]-t_start)/60, (iset.end[0]-t_start)/60, color=\"blue\", alpha=0.1) for iset in data[\"rem\"]];\n",
    "# plot green rectangles for each \"nrem\" interval\n",
    "sp2 = [ax.axvspan((iset.start[0]-t_start)/60, (iset.end[0]-t_start)/60, color=\"green\", alpha=0.1) for iset in data[\"nrem\"]];\n",
    "# plot red rectangles for each \"forward_ep\" interval\n",
    "sp3 = [ax.axvspan((iset.start[0]-t_start)/60, (iset.end[0]-t_start)/60, color=\"red\", alpha=0.1) for iset in data[\"forward_ep\"]];\n",
    "\n",
    "ax.set(xlabel=\"Time within session (minutes)\", title=\"Labelled time intervals across session\", yticks=[])\n",
    "ax.legend([sp1[0],sp2[0],sp3[0]], [\"REM sleep\",\"nREM sleep\",\"forward runs\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f922f384",
   "metadata": {},
   "source": [
    "### `eeg`\n",
    "\n",
    "\n",
    "The `eeg` field is a [`TsdFrame`](https://pynapple.org/generated/pynapple.TsdFrame.html) containing an LFP voltage trace for a single representative channel in CA1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbca019",
   "metadata": {},
   "outputs": [],
   "source": [
    "printeval(\"data['eeg']\")       # print the 2D TsdFrame\n",
    "printeval(\"data['eeg'][:,0]\")  # slice the first column, printing a 1D Tsd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f53d74a",
   "metadata": {},
   "source": [
    "### `position`\n",
    "The final object, `position`, is a [`Tsd`](https://pynapple.org/generated/pynapple.Tsd.html) containing the linearized position of the animal, in centimeters, recorded during the exploration window. This object has the field `time_support`, which is the `IntervalSet` during which position is recorded, i.e. the time window spanning the exploration period. When the animal is at rest, the position is recorded as `nan`, which means \"not a number\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f14b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "printeval(\"data['position']\")               # print the position Tsd\n",
    "printeval(\"data['position'].time_support\")  # print the position's time support\n",
    "\n",
    "# this plot demonstrates that \"forward_ep\" corresponds to positively-increasing position\n",
    "pos_start = data[\"position\"].time_support.start[0]  # grab the start of the exploration window\n",
    "fig, ax = plt.subplots(figsize=(10,3))\n",
    "l1 = ax.plot(data[\"position\"]) # plot position, where nan values are blank\n",
    "# overlay forward_ep windows\n",
    "l2 = [ax.axvspan(iset.start[0], iset.end[0], color=\"red\", alpha=0.1) for iset in data[\"forward_ep\"]];\n",
    "# set the x-limits to the first 300 seconds, set other labels\n",
    "ax.set(xlim=[pos_start,pos_start+300], ylabel=\"Position (cm)\", xlabel=\"Time (s)\", title=\"Tracked position along linear maze\")\n",
    "ax.legend([l1[0], l2[0]], [\"animal position\", \"forward run epochs\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b163a20a",
   "metadata": {},
   "source": [
    "## Identifying place fields\n",
    "Our first analysis will identify each unit's place field. We can do this using the pynapple function `compute_1d_tuning_curves` and then apply some post-processing to clean up and isolate units with strong spatial selectivity. Specifically, the following analysis will:\n",
    "1. Extract the relevant fields from the loaded dictionary\n",
    "2. Compute the tuning curves, i.e. place fields, using pynapple\n",
    "3. Apply a Gaussian filter to smooth the place fields\n",
    "4. Filter for \"good\" place cells by finding units with high spatial selectivity\n",
    "6. Sort the units in order of spatial preference\n",
    "7. Plot the resulting place fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d090277",
   "metadata": {},
   "outputs": [],
   "source": [
    "##-- 1. Grab the data --##\n",
    "spikes = data[\"units\"]                  # grab all the units\n",
    "forward_ep = data[\"forward_ep\"]         # grab the forward run epochs\n",
    "position = data[\"position\"].dropna()    # grab position, and drop nan values\n",
    "lfp = data[\"eeg\"][:,0]                  # grab the first eeg column\n",
    "\n",
    "##-- 2. Compute place fields --##\n",
    "# compute place fields in 2cm bins across linear track\n",
    "track_len = position.max() - position.min() # get total length of the track (in cm)\n",
    "nb_bins = int(track_len / 2)                # number of 2 cm bins, rounded to an integer\n",
    "# use pynapple to compute 1d tuning curves over position, returning a pandas dataframe\n",
    "place_fields = nap.compute_1d_tuning_curves(spikes, position, nb_bins = nb_bins)\n",
    "\n",
    "##-- 3. Smooth place fields --##\n",
    "# use scipy to smooth the place fields\n",
    "sigma = 2.5 # we want a 5cm Gaussian kernel, which is 5cm / 2cm/bin = 2.5 bins\n",
    "place_fields[:] = gaussian_filter1d(place_fields.values, sigma, axis=0) # update in place\n",
    "\n",
    "##-- 4. Filter units to \"good\" place cells --##\n",
    "# find all points at which the firing rate is 2 s.d. greater than the mean\n",
    "rate_95p = place_fields > (place_fields.mean() + 2*place_fields.std())\n",
    "# find whether there are 5 consecutive bins of high firing\n",
    "# we can do this by taking a rolling sum of width 5 on the boolean array, and check whether any sum is 5\n",
    "good_idx = np.any(rate_95p.rolling(5).sum() == 5, axis=0) \n",
    "# we also want the firing peak to be at least 1 Hz, and the average rate less than a theta-modulated interneuron\n",
    "good_idx = good_idx & (place_fields.max() >= 1) & (spikes.rate < 6)\n",
    "# filter the place fields using good_idx\n",
    "place_fields = place_fields.loc[:,good_idx] \n",
    "\n",
    "##-- 5. Sort units in order of preferred location --#\n",
    "# idxmax will get the index of max firing, argsort will return the index that sorts idxmax\n",
    "sort_order = place_fields.idxmax().argsort() \n",
    "sorted_place_fields = place_fields.iloc[:, sort_order] # sort units, which are the columns\n",
    "\n",
    "##-- 6. Plot results --##\n",
    "fig, axs = plt.subplots(len(place_fields.columns), 1, sharex=True, figsize=(3,8))\n",
    "plot_place_fields(sorted_place_fields, axs, title=\"Sorted place fields\", xlabel=\"Position (cm)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd45be9a",
   "metadata": {},
   "source": [
    "## Identifying place cell remapping\n",
    "\n",
    "The previous analysis computed place fields across all positions. However, place cell encoding is often selective to the direction the animal is moving along a linear maze, where place cells remap depending on which way the animal running. This means place cells can encode different locations depending on whether the animal is running forwards or backwards, leading to separable place field sequences that encode each direction. We can show this by:\n",
    "1. Compute place fields on forward runs only\n",
    "2. Compute place fields on backward runs only\n",
    "3. Plot \"forward\" and \"backward\" fields, sorted by \"forward\" preference\n",
    "4. Plot \"forward\" and \"backward\" fields, sorted by \"backward\" preference\n",
    "\n",
    "What we will see is that forward fields form a sequence when sorted by forward preference, but not backward fields; the opposite will be true when sorting by backward preference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13db63a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter spike times to good units calculated above\n",
    "good_spikes = spikes[good_idx]\n",
    "\n",
    "##-- 1. Compute place fields on forward runs --##\n",
    "# now we pass the argument ep=forward_ep to specify that tuning curves are only calculated during forward runs\n",
    "forward_fields = nap.compute_1d_tuning_curves(good_spikes, position, ep=forward_ep, nb_bins=nb_bins)\n",
    "forward_fields[:] = gaussian_filter1d(forward_fields.values, sigma, axis=0)\n",
    "\n",
    "##-- 2. Compute place fields on backward runs --##\n",
    "# all running occurs when there is a non-NaN position\n",
    "run_ep = position.time_support\n",
    "# backward runs are the set difference between all runs and forward runs\n",
    "backward_ep = run_ep.set_diff(forward_ep)\n",
    "# pass ep=backward_run to compute only during backward runs\n",
    "backward_fields = nap.compute_1d_tuning_curves(good_spikes, position, ep=backward_ep, nb_bins=nb_bins)\n",
    "backward_fields[:] = gaussian_filter1d(backward_fields.values, sigma, axis=0)\n",
    "\n",
    "# plot results\n",
    "fig = plt.figure(figsize=(7,8))\n",
    "# 3 columns, with the middle being empty for visual separation\n",
    "subfigs = fig.subfigures(1,3, width_ratios=[2,0.1,2]) \n",
    "\n",
    "##-- 3. Plot forward and backward place fields sorted by forward preference --##\n",
    "# split left column into two subcolumns for each direction\n",
    "axs = subfigs[0].subplots(len(forward_fields.columns), 2, sharex=True)\n",
    "# get sort order of forward fields\n",
    "sort_order = forward_fields.idxmax().argsort()\n",
    "# plot forward fields sorted by forward preference in left subcolumn\n",
    "plot_place_fields(forward_fields.iloc[:,sort_order], axs[:,0], \"Forward runs\", \"Position (cm)\")\n",
    "# plot backward fields sorted by forward preference in right subcolumn\n",
    "plot_place_fields(backward_fields.iloc[:,sort_order], axs[:,1], \"Backward runs\", \"Position (cm)\")\n",
    "subfigs[0].suptitle(\"Place fields sorted by forward runs\")\n",
    "\n",
    "## 4. Plot forward and backward place fields sorted by backward preference --##\n",
    "# split right column into two subcolumns\n",
    "axs = subfigs[2].subplots(len(forward_fields.columns), 2, sharex=True)\n",
    "# get sort order of backward fields\n",
    "sort_order = backward_fields.idxmax().argsort()\n",
    "# plot forward fields sorted by backward preference in left subcolumn\n",
    "plot_place_fields(forward_fields.iloc[:,sort_order], axs[:,0], \"Forward runs\", \"Position (cm)\")\n",
    "# plot backward fields sorted by backward preference in right subcolumn\n",
    "plot_place_fields(backward_fields.iloc[:,sort_order], axs[:,1], \"Backward runs\", \"Position (cm)\")\n",
    "subfigs[2].suptitle(\"Place fields sorted by backward runs\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1d5558",
   "metadata": {},
   "source": [
    "## Visualizing LFP\n",
    "While the animal is running, we can expect the LFP to be dominated by 6-12 Hz theta oscillations. We can visualize theta power over time by using the pynapple function `compute_wavelet_transform`, which computes a continuous wavelet transform over some input time series.\n",
    "\n",
    "A [continuous wavelet transform](https://en.wikipedia.org/wiki/Continuous_wavelet_transform) decomposes a signal into a set of [wavelets](https://en.wikipedia.org/wiki/Wavelet), in this case [Morlet wavelets](https://en.wikipedia.org/wiki/Morlet_wavelet), that span both frequency and time. You can think of the wavelet transform as a cross-correlation between the signal and each wavelet, giving the similarity between the signal and various frequency components at each time point of the signal. Similar to a Fourier transform, this gives us an estimate of what frequencies are dominating a signal. Unlike the Fourier tranform, however, the wavelet transform gives us this estimate as a function of time.\n",
    "\n",
    "The following example will:\n",
    "1. Restrict the data to an example run\n",
    "2. Compute the wavelet transform using pynapple\n",
    "3. Plot the raw LFP, the animal position, and the wavelet transform results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b908684",
   "metadata": {},
   "outputs": [],
   "source": [
    "##-- 1. Restrict data to example forward run --##\n",
    "# grab a single run and add two seconds to the end\n",
    "ex_run_ep = nap.IntervalSet(start=forward_ep[9].start, end=forward_ep[9].end+2)\n",
    "# restrict lfp and position to example run\n",
    "ex_lfp_run = lfp.restrict(ex_run_ep)\n",
    "ex_position = position.restrict(ex_run_ep)\n",
    "\n",
    "##-- 2. Compute wavelet transform --##\n",
    "# compute at 100 log-spaced samples between 5Hz and 200Hz\n",
    "freqs = np.geomspace(5, 200, 100)\n",
    "sample_rate = 1250 # known from manuscript methods\n",
    "# use pynapple to compute the wavelet transform, supplying a known sampling rate\n",
    "cwt_run = nap.compute_wavelet_transform(ex_lfp_run, freqs, fs=sample_rate)\n",
    "\n",
    "##-- 3. Plot results --##\n",
    "# 2 rows, 1 column, top plot smaller than bottom\n",
    "fig, axs = plt.subplots(2, 1, figsize=(10,4), constrained_layout=True, height_ratios=[0.3, 1.0], sharex=True)\n",
    "\n",
    "# plot the raw LFP on the top plot\n",
    "p1 = axs[0].plot(ex_lfp_run)\n",
    "axs[0].set(title=\"Example run\", ylabel=\"LFP (a.u.)\")\n",
    "# axs[0].margins(0)\n",
    "# plot the animal position on the top plot using a separate y-axis\n",
    "ax = axs[0].twinx()\n",
    "p2 = ax.plot(ex_position, color=\"orange\")\n",
    "ax.set_ylabel(\"Position (cm)\")\n",
    "ax.legend([p1[0], p2[0]],[\"raw LFP\",\"animal position\"])\n",
    "\n",
    "# plot the wavelet transform on the bottom\n",
    "amp = np.abs(cwt_run.values) # plot the amplitude of the transform, which it its absolute value\n",
    "cax = axs[1].pcolormesh(cwt_run.t, freqs, amp.T, cmap=\"magma\")\n",
    "axs[1].set(title=\"Wavelet decomposition\", ylabel=\"Frequency (Hz)\", xlabel=\"Time(s)\", yscale='log', yticks=freqs[::10], yticklabels=np.rint(freqs[::10]));\n",
    "axs[1].minorticks_off()\n",
    "fig.colorbar(cax,label=\"Amplitude\",location=\"right\", pad=-0.04);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b72ac3",
   "metadata": {},
   "source": [
    "## Filtering for theta\n",
    "We can isolate the theta frequency band by applying a [bandpass filter](https://en.wikipedia.org/wiki/Band-pass_filter) to the LFP trace. We can do this with the pynapple function `apply_bandpass_filter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d4ee5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# redefine example run to run only\n",
    "ex_run_ep = forward_ep[9]\n",
    "\n",
    "# use pynapple to filter the LFP between 6 and 12 Hz, supplying a known sampling rate\n",
    "theta_band = nap.apply_bandpass_filter(lfp, (6.0, 12.0), fs=sample_rate)\n",
    "\n",
    "# plot results\n",
    "plt.figure(constrained_layout=True, figsize=(10, 3))\n",
    "# plot raw lfp restricted to example run\n",
    "plt.plot(lfp.restrict(ex_run_ep), label=\"raw\")\n",
    "# plot filtered theta band restricted to example run\n",
    "plt.plot(theta_band.restrict(ex_run_ep), label=\"filtered\")\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"LFP (a.u.)\")\n",
    "plt.title(\"Bandpass filter for theta oscillations (6-12 Hz)\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c18a219",
   "metadata": {},
   "source": [
    "## Computing theta phase\n",
    "In order to examine phase precession in place cells, we need to identify the instantaneous phase of theta. We can do this by taking the angle of the [Hilbert transform](https://en.wikipedia.org/wiki/Hilbert_transform) of the band-pass filtered signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c872970e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute phase using the angle of the hilbert transform of the filtered signal\n",
    "phase = np.angle(signal.hilbert(theta_band)) \n",
    "phase = (phase + 2 * np.pi) % (2 * np.pi) # wrap to [0,2pi]\n",
    "# store phase into a pynapple object for easy time alignment\n",
    "theta_phase = nap.Tsd(t=theta_band.t, d=phase)\n",
    "\n",
    "# plot results\n",
    "fig,ax = plt.subplots(figsize=(10,2), constrained_layout=True) #, sharex=True, height_ratios=[2,1])\n",
    "# plot theta phase restricted to example run\n",
    "p1 = ax.plot(theta_phase.restrict(ex_run_ep), color='r')\n",
    "ax.set(ylabel=\"Phase (rad)\", xlabel=\"Time (s)\")\n",
    "# plot filtered LFP restricted to example run on a separate y-axis\n",
    "ax = ax.twinx()\n",
    "p2 = ax.plot(theta_band.restrict(ex_run_ep))\n",
    "ax.set_ylabel(\"LFP (a.u.)\")\n",
    "ax.legend([p1[0],p2[0]],[\"theta phase\",\"filtered LFP\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67c2f08",
   "metadata": {},
   "source": [
    "## Computing phase precession\n",
    "Phase precession is captured by the relationship between the *position* at which a place field spikes and the corresponding *phase* of theta. Specifically, there is a negative relationship: at *early positions*, cells will fire at *late phases* of theta, and at *late positions*, cells will fire at *early phases* of theta. The following example demonstrates how to find the position and phase at which an example unit fires, as well as plot multiple visualizations to demonstrate phase precession within a single run and across all sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b6485b",
   "metadata": {},
   "outputs": [],
   "source": [
    "unit = 177 # example unit with place field in the center\n",
    "\n",
    "##-- Use pynapple value_from to grab various values corresponding to each spike time --##\n",
    "spike_theta = spikes[unit].value_from(theta_band)  # filtered LFP value closest to each spike\n",
    "spike_phase = spikes[unit].value_from(theta_phase) # theta phase closest to each spike\n",
    "spike_position = spikes[unit].value_from(position) # position closest to each spike\n",
    "\n",
    "##-- Plotting --##\n",
    "# split figure into two subfigures\n",
    "fig = plt.figure(figsize=(10,5), constrained_layout=True)\n",
    "subfigs = fig.subfigures(1,2)\n",
    "\n",
    "### in left subfigure, plot data restricted to the example run\n",
    "subfigs[0].suptitle(\"Phase precession within a single forward run\")\n",
    "axs = subfigs[0].subplots(3, 1, sharex=True) # 3 subplots\n",
    "\n",
    "## left top plot - spikes vs LFP, shows a \"U\" of spike times relative to LFP\n",
    "# plot raw LFP\n",
    "axs[0].plot(lfp.restrict(ex_run_ep), alpha=0.5, label=\"raw LFP\")\n",
    "# plot filtered LFP\n",
    "axs[0].plot(theta_band.restrict(ex_run_ep), color=\"slateblue\", label=\"filtered theta\")\n",
    "# plot the value of the filtered LFP at each spike time of the example unit\n",
    "axs[0].plot(spike_theta.restrict(ex_run_ep), 'o', color=\"orange\", label=\"spike times\")\n",
    "axs[0].set(ylabel=\"LFP (a.u.)\", title=\"Spike times relative to LFP\")\n",
    "axs[0].legend(loc=\"center left\")\n",
    "\n",
    "## left middle plot - spikes vs phase, shows a negative line of spike times relative to phase\n",
    "# plot the phase of theta\n",
    "axs[1].plot(theta_phase.restrict(ex_run_ep), color=\"slateblue\", label=\"theta phase\")\n",
    "# plot the value of the phase at each spike time of the example unit\n",
    "axs[1].plot(spike_phase.restrict(ex_run_ep), 'o', color=\"orange\", label=\"spike times\")\n",
    "axs[1].set(ylabel=\"Phase (rad)\", title=\"Spike times relative to theta phase\")\n",
    "axs[1].legend(loc=\"center left\")\n",
    "\n",
    "## left bottom plot - position, shows where animal is on the track and when its in the unit's place field\n",
    "ex_position = position.restrict(ex_run_ep) # store restricted result because we use it more than once\n",
    "# plot example position as a dashed line\n",
    "axs[2].plot(ex_position, '--', color=\"green\", label=\"animal position\")\n",
    "# plot approximate field bounds in solid line\n",
    "axs[2].plot(ex_position[(ex_position > 50).values & (ex_position < 130).values], color=\"green\", lw=3, label=\"place field bounds\")\n",
    "axs[2].set(ylabel=\"Position (cm)\", xlabel=\"Time (s)\", title=\"Animal position\")\n",
    "axs[2].legend()\n",
    "\n",
    "### in right subfigure, plot session-wide visualizations\n",
    "subfigs[1].suptitle(\"Phase precession across all forward runs\")\n",
    "axs = subfigs[1].subplots(2,1, height_ratios=[2,1], sharex=True) # 2 subplots\n",
    "## top right plot - phase precession scatter plot, position vs phase\n",
    "# for each spike time, plot its corresponding position and theta phase\n",
    "axs[0].plot(spike_position.restrict(forward_ep), spike_phase.restrict(forward_ep), 'o')\n",
    "axs[0].set(ylabel=\"Phase (rad)\", title=\"Phase x position of each spike time\")\n",
    "## bottom right plot - example unit place field\n",
    "pf = forward_fields[unit]\n",
    "axs[1].fill_between(pf.index.values, np.zeros_like(pf), pf.values)\n",
    "axs[1].set(title=f\"Unit {unit} place field\", ylabel=\"Firing rate (Hz)\", xlabel=\"Position (cm)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c530846",
   "metadata": {},
   "source": [
    "## Bayesian decoding of position\n",
    "A common analysis applied to hippocampal data is [Bayesian decoding](https://pubmed.ncbi.nlm.nih.gov/9463459/) to predict the position an animal is likely at given current spiking activity. \n",
    "\n",
    "### Background\n",
    "\n",
    "Recall Bayes' rule, written here in terms of our relevant variables:\n",
    "\n",
    "$$P(position|spikes) = \\frac{P(position)P(spikes|position)}{P(spikes)}$$\n",
    "\n",
    "Our goal is to compute the unknown posterior $P(position|spikes)$ given known prior $P(position)$ and known likelihood $P(spikes|position)$. \n",
    "\n",
    "$P(position)$, also known as the *occupancy*, is the probability that the animal is occupying some position. This can be computed exactly by the proportion of the total time spent at each position, but in many cases it is sufficient to estimate the occupancy as a uniform distribution, i.e. it is equally likely for the animal to occupy any location.\n",
    "\n",
    "The next term, $P(spikes|position)$, which is the probability of seeing some sequence of spikes across all neurons at some position. Computing this relys on the following assumptions:\n",
    "1. Neurons fire according to a Poisson process (i.e. their spiking activity follows a Poisson distribution)\n",
    "2. Neurons fire independently from one another.\n",
    "\n",
    "While neither of these assumptions are strictly true, they are generally reasonable for pyramidal cells in hippocampus and allow us to simplify our computation of $P(spikes|position)$\n",
    "\n",
    "The first assumption gives us an equation for $P(spikes|position)$ for a single neuron, which we'll call $P(spikes_i|position)$ to differentiate it from $P(spikes|position) = P(spikes_1,spikes_2,...,spikes_i,...,spikes_N|position) $, or the total probability across all $N$ neurons. The equation we get is that of the Poisson distribution:\n",
    "$$\n",
    "P(spikes_i|position) = \\frac{(\\tau f_i(position))^n e^{-\\tau f_i(position)}}{n!}\n",
    "$$\n",
    "where $f_i(position)$ is the firing rate of the neuron at position $(position)$ (i.e. the tuning curve), $\\tau$ is the width of the time window over which we're computing the probability, and $n$ is the total number of times the neuron spiked in the time window of interest.\n",
    "\n",
    "The second assumptions allows us to simply combine the probabilities of individual neurons. Recall the product rule for independent events: $P(A,B) = P(A)P(B)$ if $A$ and $B$ are independent. Treating neurons as independent, then, gives us the following:\n",
    "$$\n",
    "P(spikes|position) = \\prod_i P(spikes_i|position)\n",
    "$$\n",
    "\n",
    "The final term, $P(spikes)$, is inferred indirectly using the law of total probability:\n",
    "\n",
    "$$P(spikes) = \\sum_{position}P(position,spikes) = \\sum_{position}P(position)P(spikes|position)$$\n",
    "\n",
    "Another way of putting it is $P(spikes)$ is the normalization factor such that $\\sum_{position} P(position|spikes) = 1$, which is achived by dividing the numerator by its sum.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Important:</b> Generally this method is cross-validated, which means you train the model on one set of data and test the model on a different, held-out data set. For Bayesian decoding, the \"model\" refers to the model *likelihood*, which is computed from the tuning curves.\n",
    "</div>\n",
    "\n",
    "### Running the analysis\n",
    "We can perform Baysian decoding of position using the pynapple function [`decode_1d`](https://pynapple.org/generated/pynapple.process.decoding.html#pynapple.process.decoding.decode_1d). The following example will:\n",
    "1. Cross-validation: Split the data into a training set for rate map computation, and a test set for decoding\n",
    "2. Compute tuning curves during the training set\n",
    "3. Smooth the spike counts for a better decoder estimate\n",
    "4. Decode position using pynapple\n",
    "5. Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bc05ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "##-- 1. Cross-validation setup --##\n",
    "# test set as an example trial\n",
    "ep_test = forward_ep[9]\n",
    "# hold out trial from place field computation\n",
    "ep_train = forward_ep.set_diff(ex_run_ep)\n",
    "\n",
    "##-- 2. Compute place fields --##\n",
    "# compute place fields during training set and smooth\n",
    "place_fields = nap.compute_1d_tuning_curves(spikes, position, ep=ep_train, nb_bins=nb_bins)\n",
    "place_fields[:] = gaussian_filter1d(place_fields.values, sigma, axis=0)\n",
    "\n",
    "##-- 3. Smooth spike counts --##\n",
    "# restrict all spikes to test epoch and count in 40ms bins\n",
    "counts = spikes.restrict(ep_test).count(0.04)\n",
    "# smooth counts by convolving with a length-5 window of ones (i.e. moving sum of length 5)\n",
    "# this will make bins be 40ms * 5 = 200ms wide\n",
    "smth_counts = counts.convolve(np.ones(5))\n",
    "\n",
    "##-- 4. Decode position with pynapple --##\n",
    "# decode over ep_test, giving the smoothed spike counts\n",
    "smth_decoded_position, smth_decoded_prob = nap.decode_1d(place_fields, smth_counts, ep_test, bin_size=0.2)\n",
    "\n",
    "##-- 5. Plot the results --##\n",
    "fig,ax = plt.subplots(figsize=(10, 3), constrained_layout=True)\n",
    "# plot the decoded probability of position\n",
    "c = ax.pcolormesh(smth_decoded_position.index,place_fields.index,np.transpose(smth_decoded_prob), cmap=\"magma\")\n",
    "# plot the decoded position, i.e. the position of max probability, as a dashed green line\n",
    "ax.plot(smth_decoded_position, \"--\", color=\"limegreen\", label=\"decoded position\")\n",
    "# plot the true animal position as a solid green line\n",
    "ax.plot(position.restrict(ex_run_ep), color=\"limegreen\", label=\"true position\")\n",
    "ax.legend()\n",
    "fig.colorbar(c, label=\"decoded probability\")\n",
    "ax.set(xlabel=\"Time (s)\", ylabel=\"Position (cm)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c0a617",
   "metadata": {},
   "source": [
    "## Visualization of theta sequences\n",
    "\n",
    "Theta sequences are often visualized by using Bayesian decoding on a faster time scale. The following example will repeat the steps from the previous analysis, except now predicting spiking activity in shorter time bins: specifically, during 50 ms smoothed bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd03b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##-- Smooth counts in smaller time windows --##\n",
    "counts = spikes.restrict(ep_test).count(0.01) # count in 10ms bins\n",
    "smth_counts = counts.convolve(np.ones(5))     # moving sum of length 5\n",
    "\n",
    "##-- Run decoding on test epoch --##\n",
    "smth_decoded_position, smth_decoded_prob = nap.decode_1d(place_fields, smth_counts, ep_test, bin_size=0.05)\n",
    "\n",
    "##-- Plot the decoded probability, predicted position, and true position --##\n",
    "fig, axs = plt.subplots(2, 1, figsize=(10, 4), constrained_layout=True, height_ratios=[3,1], sharex=True)\n",
    "c = axs[0].pcolormesh(smth_decoded_prob.index, smth_decoded_prob.columns, np.transpose(smth_decoded_prob), cmap=\"magma\")\n",
    "p1 = axs[0].plot(smth_decoded_position, \"--\", color=\"limegreen\")\n",
    "p2 = axs[0].plot(position.restrict(ex_run_ep), color=\"limegreen\")\n",
    "axs[0].set_ylabel(\"Position (cm)\")\n",
    "axs[0].legend([p1[0],p2[0]],[\"decoded position\",\"true position\"])\n",
    "fig.colorbar(c, label = \"predicted probability\")\n",
    "\n",
    "##-- Also plot the raw and filtered LFP aligned to the decoding --##\n",
    "axs[1].plot(lfp.restrict(ex_run_ep), label=\"raw\")\n",
    "axs[1].plot(theta_band.restrict(ex_run_ep), label=\"filtered\")\n",
    "axs[1].set_ylabel(\"LFP (a.u.)\")\n",
    "axs[1].legend()\n",
    "\n",
    "fig.supxlabel(\"Time (s)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79978c6d",
   "metadata": {},
   "source": [
    "## Fitting a GLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3b9006",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_up = data[\"position\"].interpolate(theta_phase).dropna()\n",
    "\n",
    "speed = []\n",
    "for s, e in position_up.time_support.values: # Time support contains the epochs\n",
    "    pos_ep = position_up.get(s, e)\n",
    "    speed_ep = np.abs(np.diff(pos_ep)) # Absolute difference of two consecutive points\n",
    "    speed_ep = np.pad(speed_ep, [0, 1], mode=\"edge\") # Adding one point at the end to match the size of the position array\n",
    "    speed_ep = speed_ep * sample_rate # Converting to cm/s\n",
    "    speed.append(speed_ep)\n",
    "\n",
    "speed = nap.Tsd(t=position_up.t, d=np.hstack(speed), time_support=position_up.time_support)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a151a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = np.stack((position_up, speed, theta_phase.restrict(position_up.time_support)))\n",
    "X = nap.TsdFrame(t=position_up.t, d=predictors.T, time_support=position_up.time_support)\n",
    "\n",
    "unit = 117\n",
    "bin_size = 0.001\n",
    "counts = spikes[unit].count(bin_size, ep=X.time_support)\n",
    "X = X.bin_average(bin_size)\n",
    "\n",
    "model = nmo.glm.GLM(solver_name=\"LBFGS\")\n",
    "model.fit(X, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcec9c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6ad36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
